import os  # Dosya ve dizin iÅŸlemleri iÃ§in
import numpy as np  # SayÄ±sal iÅŸlemler yapmak iÃ§in
import cv2  # GÃ¶rÃ¼ntÃ¼ iÅŸleme kÃ¼tÃ¼phanesi (Ã¶rn: gÃ¶rÃ¼ntÃ¼leri dÃ¶ndÃ¼rme, parlaklÄ±k deÄŸiÅŸtirme).
import random  # Rastgele iÅŸlemler yapmak iÃ§in
from sklearn.model_selection import train_test_split  # Veriyi eÄŸitim ve test olarak ikiye ayÄ±rmak iÃ§in.
import tensorflow as ts  # Derin Ã¶ÄŸrenme modeli iÃ§in kullanÄ±lÄ±r

to_categorical = ts.keras.utils.to_categorical  # SÄ±nÄ±f etiketlerini one-hot encoding formatÄ±na Ã§evirmek iÃ§in


# Veri artÄ±rma fonksiyonu
def augment_image(image):  # Rastgele DÃ¶ndÃ¼rme
    # 1. DÃ¶ndÃ¼rme (90, 180, 270 derece)
    if random.random() > 0.5:  # %50 olasÄ±lÄ±kla gÃ¶rÃ¼ntÃ¼ dÃ¶ndÃ¼rÃ¼lÃ¼r.
        angle = random.choice([90, 180, 270])  # DÃ¶ndÃ¼rme aÃ§Ä±sÄ± rastgele olarak 90Â°, 180Â° veya 270Â°
        # cv2.rotate fonksiyonu ile gÃ¶rÃ¼ntÃ¼ saat yÃ¶nÃ¼nde dÃ¶ndÃ¼rÃ¼lÃ¼r:
        image = cv2.rotate(image, {90: cv2.ROTATE_90_CLOCKWISE,
                                   180: cv2.ROTATE_180,
                                   270: cv2.ROTATE_90_COUNTERCLOCKWISE}[angle])

    # 2. Yatay Ã§evirme
    if random.random() > 0.5:  # %50 olasÄ±lÄ±kla gÃ¶rÃ¼ntÃ¼ yatay olarak ters Ã§evrilir
        image = cv2.flip(image, 1)

    # 3. ParlaklÄ±k deÄŸiÅŸimi
    '''
    image, 128x128 boyutunda bir numpy dizisi ve her piksel 0 ile 255 arasÄ±nda bir deÄŸer iÃ§erir
    Factor = 1.2 â†’ GÃ¶rÃ¼ntÃ¼ %20 daha parlak 
    Factor = 0.8 â†’ GÃ¶rÃ¼ntÃ¼ %20 daha karanlÄ±k
    '''
    if random.random() > 0.5:
        factor = random.uniform(0.7, 1.3)  # %70 ile %130 arasÄ±nda parlaklÄ±k deÄŸiÅŸimi
        image = np.clip(image * factor, 0, 255).astype(np.uint8)
        # GÃ¶rÃ¼ntÃ¼lerdeki piksel deÄŸerleri 0 ile 255 arasÄ±nda olmalÄ±

    # 4. GÃ¼rÃ¼ltÃ¼ ekleme
    if random.random() > 0.5:  # %50 olasÄ±lÄ±kla rastgele gÃ¼rÃ¼ltÃ¼ eklenir
        noise = np.random.randint(0, 30, image.shape, dtype='uint8')
        # ile 0-30 arasÄ±nda rastgele piksel deÄŸerleri eklenir
        image = cv2.add(image, noise)  # DeÄŸerler gÃ¶rÃ¼ntÃ¼ye eklenir

    return image


# Veri yÃ¼kleme fonksiyonu (veri artÄ±rma dahil)
def load_data(dataset_path, img_size=128, augment_factor=1, mode="train", collect_augmented_examples=True):
    categories = ["notumor", "glioma", "meningioma", "pituitary"]
    data = []
    labels = []
    augmentation_pairs = []  # ğŸ‘ˆ Orijinal ve augment edilmiÅŸ gÃ¶rÃ¼ntÃ¼leri burada saklayacaÄŸÄ±z (sadece Ã¶rnek iÃ§in)

    dataset_mode_path = os.path.join(dataset_path, mode)

    for i, category in enumerate(categories):
        folder_path = os.path.join(dataset_mode_path, category)

        if not os.path.exists(folder_path):
            continue

        for image_name in os.listdir(folder_path):
            image_path = os.path.join(folder_path, image_name)
            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) # Griye Ã§evirir

            if image is None:
                continue

            image = cv2.resize(image, (img_size, img_size)) # Boyutu kÃ¼Ã§Ã¼lt (128x128 boyutuna)
            image_reshaped = image.reshape(img_size, img_size, 1) # 4D ÅŸekle dÃ¶nÃ¼ÅŸtÃ¼rme (128,128,1)
            data.append(image_reshaped)
            labels.append(i) # Etiketler, sÄ±nÄ±f numarasÄ± olarak eklenir

            if mode == "train": # Sadece eÄŸitim setinde veri artÄ±rma yap
            # Veri artÄ±rma yaparak ekstra gÃ¶rÃ¼ntÃ¼ler oluÅŸtur    
                for _ in range(augment_factor): # Her gÃ¶rÃ¼ntÃ¼ iÃ§in augment_factor kadar yeni veri Ã¼ret
                    augmented_image = augment_image(image) # Veri artÄ±rma fonksiyonu (augment_image)
                    augmented_reshaped = augmented_image.reshape(img_size, img_size, 1) # CNN'e uygun hale getirme, 4D ÅŸekle dÃ¶nÃ¼ÅŸtÃ¼rme
                    data.append(augmented_reshaped) # listeye ekleme iÅŸlemi
                    labels.append(i)

                    # ğŸ‘‡ Sadece ilk birkaÃ§ Ã¶rnek iÃ§in orijinal ve augment edilmiÅŸ halini kaydet
                    if collect_augmented_examples and len(augmentation_pairs) < 30:
                        augmentation_pairs.append((image, augmented_image))

    data = np.array(data) / 255.0 # data iÃ§indeki sonuÃ§ verilerine normalizasyon (0-1 aralÄ±ÄŸÄ±na Ã§ekme) uygulama
    labels = to_categorical(np.array(labels), num_classes=4) # numpy dizisine Ã§evirme ve One-hot encoding.
    # Her etiket, uzunluÄŸu num_classes=4 olan bir diziye Ã§evrildi.
    # Etiketlerin sÄ±ralama deÄŸil, kategorik olduÄŸunu anlatmak iÃ§in [0,1,1,1], [0,1,0,0] ...
    # sÄ±ralÄ± bir deÄŸer gibi algÄ±lanmamasÄ± iÃ§in one-hot encoding

    if mode == "train":
        return data, labels, augmentation_pairs
    else:
        return data, labels


    # return train_test_split(data, labels, test_size=0.2, random_state=42)
    # random_state = 42 :
    # Verinin bÃ¶lÃ¼nmesini rastgele yapmak ama her Ã§alÄ±ÅŸtÄ±rmada aynÄ± sonuÃ§ almak iÃ§in
    # Her Ã§alÄ±ÅŸtÄ±rmada aynÄ± eÄŸitim ve test setleri oluÅŸur
    # Bu, modelin tutarlÄ± ÅŸekilde test edilmesini saÄŸlar
    # EÄŸer random_state verilmezse :
    # train_test_split her Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda farklÄ± ÅŸekilde veri bÃ¶ler.
    # Yani bir Ã§alÄ±ÅŸtÄ±rmada image1 test setine giderken, baÅŸka bir Ã§alÄ±ÅŸtÄ±rmada eÄŸitim setine gidebilir.
